{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b0333f4e",
      "metadata": {
        "id": "b0333f4e"
      },
      "source": [
        "# Light GBM\n",
        "\n",
        "Light GBM, XGBoost'un eğitim süresi performansını artırmaya yönelik geliştirilen bir diğer GBM türüdür.\n",
        "\n",
        "* Daha performanslı\n",
        "* Level-wise büyüme stratejisi yerine Leaf-wise büyüme stratejisi\n",
        "* Breadth-first search (BFS) yerine depth-first search (DFS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4736d024",
      "metadata": {
        "id": "4736d024"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a4988e5a",
      "metadata": {
        "id": "a4988e5a"
      },
      "source": [
        "xgboost, Level-wise büyüme stratejisini kullanır ve Breadth-first search (BFS) yapar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d09ff8",
      "metadata": {
        "id": "28d09ff8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0aff5c",
      "metadata": {
        "id": "1f0aff5c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "205cc81d",
      "metadata": {
        "id": "205cc81d"
      },
      "source": [
        "# Light GBM - Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "18c33b48",
      "metadata": {
        "id": "18c33b48"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn import model_selection\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "# uyarılar gözükmesin\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# bilgilerin gözükmesi için\n",
        "from sklearn import set_config\n",
        "set_config(print_changed_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a2437471",
      "metadata": {
        "id": "a2437471"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "hit = pd.read_csv(\"Hitters.csv\")\n",
        "df = hit.copy()\n",
        "df = df.dropna()\n",
        "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
        "y = df[\"Salary\"]\n",
        "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
        "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e996507d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e996507d",
        "outputId": "7b74075f-f22b-437d-ee8e-3743675fc1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d9bc6d",
      "metadata": {
        "id": "17d9bc6d"
      },
      "outputs": [],
      "source": [
        "# conda install -c conda-forge lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e7766992",
      "metadata": {
        "id": "e7766992"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "85e2da38",
      "metadata": {
        "id": "85e2da38"
      },
      "outputs": [],
      "source": [
        "lgbm = LGBMRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e9cfc4f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cfc4f9",
        "outputId": "0f46853c-a532-4a75-d95b-65658ef3666f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 831\n",
            "[LightGBM] [Info] Number of data points in the train set: 197, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 543.483442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "lgbm_model = lgbm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22852f4b",
      "metadata": {
        "id": "22852f4b"
      },
      "source": [
        "# Light GBM - Tahmin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9e44f8c8",
      "metadata": {
        "id": "9e44f8c8"
      },
      "outputs": [],
      "source": [
        "y_pred = lgbm_model.predict(X_test,\n",
        "                            num_iteration = lgbm_model.best_iteration_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "2819e74e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2819e74e",
        "outputId": "e1463c60-f6ee-4443-a34c-ca6469b77883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363.8712087611089"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a917cd",
      "metadata": {
        "id": "01a917cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1204ec91",
      "metadata": {
        "id": "1204ec91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ff4d4cc5",
      "metadata": {
        "id": "ff4d4cc5"
      },
      "source": [
        "# Light GBM - Model Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e5d8a4a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "e5d8a4a3",
        "outputId": "e1261da9-f69c-42d1-d798-9fab51d46363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=None, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(boosting_type=&#x27;gbdt&#x27;, class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type=&#x27;split&#x27;, learning_rate=0.1, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=None, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(boosting_type=&#x27;gbdt&#x27;, class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type=&#x27;split&#x27;, learning_rate=0.1, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=None, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "lgbm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "46cf5678",
      "metadata": {
        "id": "46cf5678"
      },
      "outputs": [],
      "source": [
        "lgbm_grid = {\n",
        "    \"colsample_bytree\":[0.4,0.5,0.6,0.9,1],\n",
        "    \"learning_rate\":[0.01,0.1,0.5,1],\n",
        "    \"n_estimators\":[20,40,100,200,500,1000],\n",
        "    \"max_depth\":[1,2,3,4,5,6,7,8]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8caff128",
      "metadata": {
        "id": "8caff128"
      },
      "source": [
        "9600 ağaç, xgboost'un 3 katı 3 dakikadan daha az bir şekilde bu işlemi tamamlarsa lightgbm daha hızlıdır diyebiliriz. lightgbm, xgboost'un 3 katından daha fazla fit işlemini 1.5 dakikada tamamladı."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "5d42c1d8",
      "metadata": {
        "id": "5d42c1d8"
      },
      "outputs": [],
      "source": [
        "lgbm = LGBMRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ce71d64d",
      "metadata": {
        "id": "ce71d64d"
      },
      "outputs": [],
      "source": [
        "lgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs=-1,verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1877ec39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "1877ec39",
        "outputId": "42dbe155-547b-420a-c1b7-6726a2a56a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 960 candidates, totalling 9600 fits\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 831\n",
            "[LightGBM] [Info] Number of data points in the train set: 197, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 543.483442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
              "                                     colsample_bytree=1.0,\n",
              "                                     importance_type='split', learning_rate=0.1,\n",
              "                                     max_depth=-1, min_child_samples=20,\n",
              "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_leaves=31, objective=None,\n",
              "                                     random_state=None, reg_alpha=0.0,\n",
              "                                     reg_lambda=0.0, subsample=1.0,\n",
              "                                     subsample_for_bin=200000,\n",
              "                                     subsample_freq=0),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'colsample_bytree': [0.4, 0.5, 0.6, 0.9, 1],\n",
              "                         'learning_rate': [0.01, 0.1, 0.5, 1],\n",
              "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],\n",
              "                         'n_estimators': [20, 40, 100, 200, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=LGBMRegressor(boosting_type=&#x27;gbdt&#x27;, class_weight=None,\n",
              "                                     colsample_bytree=1.0,\n",
              "                                     importance_type=&#x27;split&#x27;, learning_rate=0.1,\n",
              "                                     max_depth=-1, min_child_samples=20,\n",
              "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_leaves=31, objective=None,\n",
              "                                     random_state=None, reg_alpha=0.0,\n",
              "                                     reg_lambda=0.0, subsample=1.0,\n",
              "                                     subsample_for_bin=200000,\n",
              "                                     subsample_freq=0),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;colsample_bytree&#x27;: [0.4, 0.5, 0.6, 0.9, 1],\n",
              "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.5, 1],\n",
              "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8],\n",
              "                         &#x27;n_estimators&#x27;: [20, 40, 100, 200, 500, 1000]},\n",
              "             pre_dispatch=&#x27;2*n_jobs&#x27;, refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=LGBMRegressor(boosting_type=&#x27;gbdt&#x27;, class_weight=None,\n",
              "                                     colsample_bytree=1.0,\n",
              "                                     importance_type=&#x27;split&#x27;, learning_rate=0.1,\n",
              "                                     max_depth=-1, min_child_samples=20,\n",
              "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_leaves=31, objective=None,\n",
              "                                     random_state=None, reg_alpha=0.0,\n",
              "                                     reg_lambda=0.0, subsample=1.0,\n",
              "                                     subsample_for_bin=200000,\n",
              "                                     subsample_freq=0),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;colsample_bytree&#x27;: [0.4, 0.5, 0.6, 0.9, 1],\n",
              "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.5, 1],\n",
              "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8],\n",
              "                         &#x27;n_estimators&#x27;: [20, 40, 100, 200, 500, 1000]},\n",
              "             pre_dispatch=&#x27;2*n_jobs&#x27;, refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(boosting_type=&#x27;gbdt&#x27;, class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type=&#x27;split&#x27;, learning_rate=0.1, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=None, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "lgbm_cv_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "73279462",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73279462",
        "outputId": "6f5e64ca-3fed-4676-8d04-d198cc5aff0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.5,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 6,\n",
              " 'n_estimators': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# modelin optimum parametre değerleri\n",
        "lgbm_cv_model.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "1f2f0b81",
      "metadata": {
        "id": "1f2f0b81"
      },
      "outputs": [],
      "source": [
        "# final modelimizi oluşturalım\n",
        "lgbm_tuned = LGBMRegressor(learning_rate = 0.1,\n",
        "                          max_depth = 6,\n",
        "                          n_estimators = 20,\n",
        "                          colsample_bytree = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ff81dce1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff81dce1",
        "outputId": "281f31c6-05ea-4140-8610-34844026f44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 831\n",
            "[LightGBM] [Info] Number of data points in the train set: 197, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score 543.483442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "lgbm_tuned = lgbm_tuned.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c00255",
      "metadata": {
        "id": "28c00255"
      },
      "outputs": [],
      "source": [
        "# final modeli için test hatası"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "1d951187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d951187",
        "outputId": "31cf22e9-95e6-4258-e4c6-8bfb1924ba06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ],
      "source": [
        "y_pred = lgbm_tuned.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9cef361e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cef361e",
        "outputId": "5f29be2b-cb58-4055-df2c-3e21a7ec59b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375.6085209015434"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "np.sqrt(mean_squared_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "923606ba",
      "metadata": {
        "id": "923606ba"
      },
      "source": [
        "ligthGBM, XGBoost'a göre..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}